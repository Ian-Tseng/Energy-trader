{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5374d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "# from torch import nn\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import argparse\n",
    "import loader ##  loader data and process.\n",
    "import model  ##  Model architecture.\n",
    "\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "back = 10\n",
    "infer = 1\n",
    "skip_min = 5\n",
    "end_max = 0.2\n",
    "\n",
    "class Trader:\n",
    "\n",
    "    def __init__(self, train_path=None, test_path=None, generation_data_path= None, consumption_data_path= None):\n",
    "\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.generation_data_path= generation_data_path\n",
    "        self.consumption_data_path= consumption_data_path\n",
    "\n",
    "    def load(self):\n",
    "\n",
    "        loader_data = loader.data(self.test_path, self.test_path)\n",
    "        loader_data.scaler()\n",
    "        tr_x, tr_y, te_x, _ = loader_data.initialize(\n",
    "            back=back, infer=infer, valid_size=0\n",
    "        )\n",
    "        self.scale_fun = loader_data.scaler_fun#[0].inverse_transform\n",
    "        self.train_x = tr_x\n",
    "        self.train_y = tr_y\n",
    "        self.test_x = te_x\n",
    "        return\n",
    "\n",
    "    def load_model(self, path):\n",
    "\n",
    "        # model_gru = model.GRU()\n",
    "        # model_gru.load_state_dict(torch.load(path))\n",
    "        model_gru = torch.load(path)\n",
    "        \n",
    "        model_gru.eval()\n",
    "        self.model_gru = model_gru\n",
    "        return\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        train_set_x = self.train_x\n",
    "        train_set_y = self.train_y\n",
    "        model_gru = model.GRU()\n",
    "        criterion = torch.nn.MSELoss(reduction='mean')\n",
    "        optimiser = torch.optim.Adam(model_gru.parameters(), lr=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimiser, T_max=10)\n",
    "        pass\n",
    "\n",
    "        num_epochs = 100 \n",
    "        hist = np.zeros(num_epochs)\n",
    "        start_time = time.time()\n",
    "        model_gru.train()\n",
    "        for t in range(num_epochs):\n",
    "\n",
    "            train_y_hat = model_gru(train_set_x)\n",
    "            train_y = torch.cat([train_set_y['generation'], train_set_y['consumption']], axis=1)\n",
    "            \n",
    "            loss = criterion(train_y_hat, train_y)\n",
    "            if((t+1)%10==0): print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "            hist[t] = loss.item()\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            scheduler.step()\n",
    "            continue\n",
    "\n",
    "        training_time = time.time()-start_time    \n",
    "        print(\"Training time: {}\".format(training_time))\n",
    "        pass\n",
    "\n",
    "        self.model_gru = model_gru.eval()\n",
    "        return\n",
    "\n",
    "    def predict(self, test_input):\n",
    "\n",
    "        self.model_gru.eval()\n",
    "        test_score = self.model_gru(test_input).detach().numpy()\n",
    "        # print(test_score[:,0:1].shape)\n",
    "\n",
    "        test_gen_prediction = self.scale_fun[1].inverse_transform(test_score[:,0:1])\n",
    "        test_con_prediction = self.scale_fun[2].inverse_transform(test_score[:,1:2])\n",
    "        return([test_gen_prediction, test_con_prediction])\n",
    "\n",
    "    \n",
    "def init_predict(generation_data_path, consumption_data_path):\n",
    "  \n",
    "   # training_dir = os.path.join(os.getcwd(), \"energy_data\")\n",
    "    testing_gen = generation_data_path \n",
    "    testing_con = consumption_data_path \n",
    "    model_path = os.path.join(os.getcwd(), \"model.h5\")\n",
    "    predict_data_path = os.path.join(os.getcwd(), \"predict_data.csv\")\n",
    "   \n",
    "        \n",
    "    train_data_list= []\n",
    "  \n",
    "    test_path = os.path.join(os.getcwd(), 'test_data.csv')\n",
    "   \n",
    "    test_gen = pd.read_csv(testing_gen, header=None)\n",
    "    test_gen= test_gen[1:]\n",
    "    test_gen.columns = ['time', 'generation']\n",
    "    test_con = pd.read_csv(testing_con, header=None)\n",
    "    test_con= test_con[1:]\n",
    "    test_con.columns = ['time', 'sonsumption']\n",
    "    test_data = pd.merge(test_gen, test_con, how='inner', on='time')\n",
    "   \n",
    "    test_data= test_data[:24]\n",
    "    out = test_data[['time']].copy()\n",
    "    print ('test_data', test_data[:24])\n",
    "    \n",
    "    test_data.to_csv(test_path, header=None, index=False)\n",
    "    \n",
    "    trader = Trader(train_path=None, test_path=test_path)\n",
    "    trader.load()\n",
    "    trader.load_model(path=model_path)\n",
    "\n",
    "    max_length = len(trader.test_x['time'])\n",
    "    scale_fun = trader.scale_fun\n",
    "    loop = range(max_length)  ##  Test data length.\n",
    "    \n",
    "    # scale_fun = trader.scale_fun\n",
    "    # max_length = len(trader.test_x['open'])\n",
    "    # endpoint = max_length - int(max_length * end_max)\n",
    "    # scale_fun = trader.scale_fun\n",
    "    test_x = trader.test_x\n",
    "    # skip = min(back, skip_min)\n",
    "    # act_list = []\n",
    "    # have = False\n",
    "    # out = pd.DataFrame()\n",
    "    time_slot = []\n",
    "    gen = []\n",
    "    con = []\n",
    "    for d in loop:\n",
    "        # print(test_x['time'])\n",
    "        # if(d>0): time_slot += [test_x['time'][d:d+1][0][0]]\n",
    "        test_input = {\n",
    "            'generation':test_x['generation'][d:d+1],\n",
    "            'consumption':test_x['consumption'][d:d+1]\n",
    "        }\n",
    "        # now_open_price = scale_fun[1].inverse_transform(test_input['generation']).flatten()[-1].item()\n",
    "        # now_open_price = scale_fun[2].inverse_transform(test_input['consumption']).flatten()[-1].item()\n",
    "        next_day_pred = trader.predict(test_input)\n",
    "        # print(next_day_pred)\n",
    "        # next_day_gen = scale_fun[1].inverse_transform(next_day_pred[0])\n",
    "        # next_day_con = scale_fun[2].inverse_transform(next_day_pred[1])\n",
    "        next_day_gen = next_day_pred[0].item()\n",
    "        next_day_con = next_day_pred[1].item()\n",
    "        # print(next_day_con.item())\n",
    "        # next_day_time = test_input['time']\n",
    "        # print(test_x['time'][d:d+1])\n",
    "        # print(test_x['time'][d:d+1][0][0])\n",
    "        # if(d==(max_length-1)): time_slot += [test_x['time'][d:d+1][0][0][1]]\n",
    "        # row = pd.DataFrame({\"time\":time_slot, \"generation\": [next_day_gen.item()], \"consumption\":[next_day_con.item()]})\n",
    "        gen += [next_day_gen]\n",
    "        con += [next_day_con]\n",
    "        # out = pd.concat([out,row],axis=0)\n",
    "        continue\n",
    "        # print(next_day_gen)\n",
    "        # print(next_day_time)\n",
    "    # print(out)\n",
    "    out_gencon = pd.concat([out, pd.DataFrame({\"generation\": gen, \"consumption\":con})], axis=1)\n",
    "    # print(out_gencon)\n",
    "    out_gencon.to_csv(predict_data_path, index=False)\n",
    "            \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59b9afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "# You should not modify this part.\n",
    "def config():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--consumption\", default=\"./sample_data/consumption.csv\", help=\"input the consumption data path\")\n",
    "    parser.add_argument(\"--generation\", default=\"./sample_data/generation.csv\", help=\"input the generation data path\")\n",
    "    parser.add_argument(\"--bidresult\", default=\"./sample_data/bidresult.csv\", help=\"input the bids result path\")\n",
    "    parser.add_argument(\"--output\", default=\"output.csv\", help=\"output the bids path\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def output(path, data):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"time\", \"action\", \"target_price\", \"target_volume\"])\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "    return\n",
    "# You should not modify this part.\n",
    "#################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def gen_val_data(total_data_list, consumption_data_name, generation_data_name):\n",
    "    a= 300\n",
    "    b= a+ 50                           \n",
    "    rand_range_start= random.randrange(a, b)\n",
    "  \n",
    "    new_data_list= total_data_list[rand_range_start:]\n",
    "    data_len= 7* 24\n",
    "    target_data_list= []\n",
    "    for i, c in enumerate(new_data_list):\n",
    "        time_in_h= c[0].split(' ')[1]\n",
    "       \n",
    "        if time_in_h== '00:00:00':\n",
    "            target_data_list= new_data_list[i:i+ data_len]\n",
    "            break\n",
    "    generation_data= [[i[0], i[1]] for i in target_data_list]\n",
    "    consumption_data= [[i[0], i[2]] for i in target_data_list]\n",
    "    \n",
    "    generation_data_dir= os.path.join(os.getcwd(), generation_data_name)            \n",
    "    consumption_data_dir= os.path.join(os.getcwd(), consumption_data_name)\n",
    "    \n",
    "    with open(generation_data_dir, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerows(generation_data)\n",
    "    with open(consumption_data_dir, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerows(consumption_data)\n",
    "    \n",
    "        \n",
    " \n",
    "\n",
    "def get_all_data(target_dir):\n",
    "    data_dir_index_list= []\n",
    "  \n",
    "    for i in glob.iglob(os.path.join(target_dir, \"*csv\")):\n",
    "        title, ext= os.path.splitext(os.path.basename(i))\n",
    "        if not 'target' in title:\n",
    "            continue\n",
    "     \n",
    "        data_dir_index_list.append(i)\n",
    " \n",
    "    total_data_list= []\n",
    "    for data_dir in data_dir_index_list:\n",
    "        with open(data_dir, 'r', newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            data_list= [i for i in reader]\n",
    "            total_data_list+= data_list[1:]\n",
    "            \n",
    "    return total_data_list\n",
    "           \n",
    "        \n",
    "def gen_bidresult(bid_result_data_name):\n",
    "    bid_result_data_dir= os.path.join(os.getcwd(), bid_result_data_name)\n",
    "    header= ['time', 'action', 'target_price', 'target_volume', 'trade_price', 'trade_volume', 'status']\n",
    "    with open(bid_result_data_dir, 'w', newline='') as csvfile:\n",
    "        writer= csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(header)\n",
    "        \n",
    "def get_peak_time(data_list):\n",
    "    \n",
    "    # For consumption peak\n",
    "    data_list= sorted(data_list[1:],  key = lambda s: float(s[2]))\n",
    "    high_peak_time_list= []\n",
    "    for i in data_list[0: 1500]:\n",
    "        time_in_h= i[0].split(' ')[1]\n",
    "        high_peak_time_list.append(time_in_h)\n",
    "    \n",
    "    unique, counts = np.unique(np.array(high_peak_time_list), return_counts=True)\n",
    "    high_peak_time_count= dict(zip(unique, counts))\n",
    "\n",
    "    high_peak_time_count= {k: v for k, v in (sorted(high_peak_time_count.items(), key=lambda item: item[1], reverse=True))}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    loew_peak_time_data_list= sorted(data_list[1:],  key = lambda s: float(s[2]), reverse=True)  \n",
    "    low_peak_time_list= []\n",
    "    for i in loew_peak_time_data_list[0: 1500]:\n",
    "      \n",
    "        low_peak_time_list.append(i[0].split(' ')[1])\n",
    "    unique, counts = np.unique(np.array(low_peak_time_list), return_counts=True)\n",
    "    low_peak_time_count= dict(zip(unique, counts))\n",
    "    low_peak_time_count= {k: v for k, v in (sorted(low_peak_time_count.items(), key=lambda item: item[1], reverse=True))}\n",
    "   \n",
    "    \n",
    "    \n",
    "    # # For generate peak \n",
    "    high_generate_peak_time_data_list= sorted(data_list[1:],  key = lambda s: float(s[1]), reverse= True)\n",
    "    high_peak_time_list= []\n",
    "    for i in high_generate_peak_time_data_list[0: 1500]:\n",
    "\n",
    "        time_in_h= i[0].split(' ')[1] \n",
    "        high_peak_time_list.append(time_in_h)\n",
    "    \n",
    "    unique, counts = np.unique(np.array(high_peak_time_list), return_counts=True)\n",
    "    high_peak_time_count= dict(zip(unique, counts))\n",
    "\n",
    "    high_peak_time_count= {k: v for k, v in (sorted(high_peak_time_count.items(), key=lambda item: item[1], reverse=True))}\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    low_generate_peak_time_data_list= sorted(data_list[1:],  key = lambda s: float(s[1]))\n",
    "    low_peak_time_list= []\n",
    "    for i in low_generate_peak_time_data_list[0: 1500]:\n",
    " \n",
    "        low_peak_time_list.append(i[0].split(' ')[1])\n",
    "    unique, counts = np.unique(np.array(low_peak_time_list), return_counts=True)\n",
    "    low_peak_time_count= dict(zip(unique, counts))\n",
    "    low_peak_time_count= {k: v for k, v in (sorted(low_peak_time_count.items(), key=lambda item: item[1], reverse=True))}\n",
    "   \n",
    "    \n",
    "def get_gen_consum_progress(data_list):\n",
    "    next_day_count=0 \n",
    "    total_gen= 0\n",
    "    total_consum= 0\n",
    "    \n",
    "    for i, data in enumerate(data_list):\n",
    "        time= data[0].split(' ')[1]\n",
    "        if time== '00:00:00' and i!= 0:\n",
    "            next_day_count+= 1\n",
    "            break\n",
    "        total_gen+= float(data[1])\n",
    "        total_consum+= float(data[2])\n",
    "        print ('time', time, 'total_gen', total_gen, 'total_consum', total_consum)\n",
    "        \n",
    "def get_request_gen_rate(data_list):\n",
    "    \n",
    "    # For consumption peak\n",
    "    data_list= sorted(data_list[1:],  key = lambda s: float(s[2]))\n",
    "    high_peak_time_list= []\n",
    "    request_gen_rate_dict= dict()\n",
    "    total_gen= 'total_gen'\n",
    "    total_consum= 'total_consum'\n",
    "   \n",
    "    for i, c in enumerate(data_list):\n",
    "        \n",
    "        request_gen_rate= 'request_gen_rate'\n",
    "        \n",
    "        \n",
    "            \n",
    "        time_in_h= c[0].split(' ')[1]\n",
    "        \n",
    "        if not time_in_h in request_gen_rate_dict:\n",
    "            request_gen_rate_dict[time_in_h]= {total_gen: 0, total_consum: 0}\n",
    "            request_gen_rate_dict[time_in_h][total_gen]= float(c[1])\n",
    "            request_gen_rate_dict[time_in_h][total_consum]= float(c[2])\n",
    "            \n",
    "        update_gen= request_gen_rate_dict[time_in_h][total_gen]+ float(c[1])\n",
    "        update_consum= request_gen_rate_dict[time_in_h][total_consum]+float(c[2])\n",
    "        request_gen_rate_dict[time_in_h][total_gen]= update_gen\n",
    "        request_gen_rate_dict[time_in_h][total_consum]= update_consum\n",
    "       \n",
    "        if update_gen== 0:\n",
    "            update_gen= 0.00000001\n",
    "        update_request_gen_rate= update_consum/ update_gen\n",
    "        \n",
    "        request_gen_rate_dict[time_in_h][request_gen_rate]= update_request_gen_rate\n",
    "            \n",
    "    \n",
    "    request_gen_rate_list= []\n",
    "    for i in request_gen_rate_dict:\n",
    "        request_gen_rate_list.append([i, request_gen_rate_dict[i][request_gen_rate]])\n",
    "      \n",
    "    \n",
    "    request_gen_rate_list= sorted(request_gen_rate_list,  key = lambda s: float(s[1]))\n",
    "    for i in request_gen_rate_list:\n",
    "        print (i)\n",
    "    return request_gen_rate_list\n",
    "\n",
    "def check_in_target_time(h, request_gen_rate_list):\n",
    "    in_buy_time= False\n",
    "    in_sell_time= False\n",
    "    sell_range= range(17, 23)\n",
    "    h_h= int(h[: 2])\n",
    "   \n",
    "    request_gen_rate_dict= dict(request_gen_rate_list)\n",
    "    if request_gen_rate_dict[h]< 1:\n",
    "        in_buy_time= True\n",
    "    if request_gen_rate_dict[h]> 200 and h_h in sell_range:\n",
    "        in_sell_time= True\n",
    "        \n",
    "    return in_buy_time, in_sell_time\n",
    "\n",
    "def get_price(h, action, amount, market_price,request_gen_rate_list):\n",
    "   \n",
    "    price_list= []\n",
    "    bill_list= []\n",
    "    sell_discount_range= reversed(np.arange(5, 8, 0.5))\n",
    "    buy_discount_range= np.arange(5, 8, 0.5)\n",
    "   \n",
    "    if action== [0, 1]: # Buy\n",
    "        index_list= [i[0] for i in request_gen_rate_list]\n",
    "        priority= index_list.index(h)\n",
    "        for i in buy_discount_range:\n",
    "            price_list.append(market_price* i/ 10)\n",
    "            bill_list.append(market_price- (market_price* i/ 10))\n",
    "    else:   # Sell\n",
    "        index_list= [i[0] for i in reversed(request_gen_rate_list)]\n",
    "        priority= index_list.index(h)\n",
    "        for i in sell_discount_range:\n",
    "            price_list.append(market_price* i/ 10)\n",
    "            bill_list.append(market_price* i/ 10)\n",
    "            \n",
    "\n",
    "    return price_list, bill_list, priority\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "def init_agent(info_in_hour_list, request_gen_rate_list):\n",
    "    market_price=   2.4738 # 2.5256\n",
    "    action= [0, 1] # [1 if Sell 0 else, 1 if Buy 0 else] # default state= [0, 0] or [1, 0]\n",
    "    # Default upper price= market price\n",
    "    total_energy= 0\n",
    "    total_consumption= 0\n",
    "    ori_energy= 0\n",
    "    ori_consumption= 0\n",
    "    action_list= []\n",
    "    action_history_list= []\n",
    "    state_history_list= []\n",
    "    total_bill_arr= np.zeros(6)\n",
    "    total_bill_buy_arr= np.zeros(6)\n",
    "    total_bill_sell_arr= np.zeros(6)\n",
    "    for c, (time , generate, consumption) in enumerate(info_in_hour_list):\n",
    "        if c== 0 or len(generate)== 0:\n",
    "            continue\n",
    "      \n",
    "        generate= float(generate)\n",
    "        consumption= float(consumption)\n",
    "        time_in_h= time.split(' ')[1]\n",
    "            \n",
    "        if generate- consumption> 0:\n",
    "            state_in_h= [1, 0]\n",
    "        else:\n",
    "            state_in_h= [0, 0]\n",
    "        \n",
    "        \n",
    "        if len(state_history_list)> 0:\n",
    "            last_state= state_history_list[-1][1]\n",
    "            update_state= (np.array(state_in_h)+ np.array(last_state)).tolist()\n",
    "            for i, c in enumerate(update_state):\n",
    "                if c>0:\n",
    "                    update_state[i]= 1\n",
    "                else:\n",
    "                    update_state[i]= 0\n",
    "                    \n",
    "        else:\n",
    "            update_state= state_in_h\n",
    "        \n",
    "        \n",
    "        \n",
    "        total_energy+= generate\n",
    "        total_consumption+= consumption\n",
    "        in_buy_time, in_sell_time= check_in_target_time(time_in_h, request_gen_rate_list)\n",
    "        price= None\n",
    "        amount= None\n",
    "        action= None\n",
    "        action_name= None\n",
    "        prioirty= None\n",
    "        \n",
    "        \n",
    "        ori_energy+= generate\n",
    "        ori_consumption+= consumption\n",
    "        \n",
    "        amount= total_energy- total_consumption\n",
    "        if 1 in update_state and total_energy- total_consumption> 0 and in_sell_time and amount!= 0: # Sell action\n",
    "          \n",
    "            action= [1, 0]\n",
    "            total_energy-= amount\n",
    "            remaining= total_energy- total_consumption\n",
    "            price_range, bill_list, prioirty= get_price(time_in_h, action, amount, market_price, request_gen_rate_list)\n",
    "            \n",
    "            if action== [1, 0]:\n",
    "                action_name= 'sell'\n",
    "            else:\n",
    "                action_name= 'buy'\n",
    "            for i, price in enumerate(price_range):\n",
    "                action_list.append([time_in_h, action_name, price, amount])\n",
    "                action_history_list.append([time_in_h, action, price, amount, remaining, bill_list[i]])\n",
    "                state_history_list.append([time_in_h, update_state, action, price, amount, remaining, bill_list[i]])\n",
    "            total_bill_sell_arr= total_bill_sell_arr+ np.array(bill_list)* amount\n",
    "            \n",
    "        if update_state== [0, 0] and in_buy_time:  # Buy action\n",
    "            action= [0, 1]\n",
    "            amount= abs(amount)\n",
    "            total_energy+= amount\n",
    "            remaining= total_energy- total_consumption\n",
    "            price_range, bill_list, prioirty= get_price(time_in_h, action, amount, market_price, request_gen_rate_list)\n",
    "            \n",
    "            if action== [1, 0]:\n",
    "                action_name= 'sell'\n",
    "            else:\n",
    "                action_name= 'buy'\n",
    "            for i, price in enumerate(price_range):\n",
    "                action_list.append([time_in_h, action_name, price, amount])\n",
    "                action_history_list.append([time_in_h, action, price, amount, remaining, bill_list[i]])\n",
    "                state_history_list.append([time_in_h, update_state, action, price, amount, remaining, bill_list[i]])\n",
    "            total_bill_buy_arr= total_bill_buy_arr+ np.array(bill_list)* amount\n",
    "            \n",
    "        if in_sell_time:  # Append sell\n",
    "            print ('in sell time')\n",
    "            action= [1, 0]\n",
    "            amount= abs(total_energy- total_consumption)* 0.8\n",
    "            if amount== 0:\n",
    "                continue\n",
    "            total_energy-= amount\n",
    "            remaining= total_energy- total_consumption\n",
    "            price_range, bill_list, prioirty= get_price(time_in_h, action, amount, market_price, request_gen_rate_list)\n",
    "           \n",
    "            \n",
    "            if action== [1, 0]:\n",
    "                action_name= 'sell'\n",
    "            else:\n",
    "                action_name= 'buy'\n",
    "                \n",
    "            for i, price in enumerate(price_range):\n",
    "                action_list.append([time_in_h, action_name, price, amount])\n",
    "                action_history_list.append([time_in_h, action, price, amount, remaining, bill_list[i]])\n",
    "                state_history_list.append([time_in_h, update_state, action, price, amount, remaining, bill_list[i]])\n",
    "            total_bill_sell_arr= total_bill_sell_arr+ np.array(bill_list)* amount\n",
    "            \n",
    "        if in_buy_time:  # Append buy\n",
    "          \n",
    "            action= [0, 1]\n",
    "            amount= abs(total_energy- total_consumption)* 0.8\n",
    "            total_energy+= amount\n",
    "            remaining= total_energy- total_consumption\n",
    "            price_range, bill_list, prioirty= get_price(time_in_h, action, amount, market_price, request_gen_rate_list)\n",
    "            \n",
    "            \n",
    "            if action== [1, 0]:\n",
    "                action_name= 'sell'\n",
    "            else:\n",
    "                action_name= 'buy'\n",
    "                \n",
    "            for i, price in enumerate(price_range):\n",
    "                action_list.append([time_in_h, action_name, price, amount])\n",
    "                action_history_list.append([time_in_h, action, price, amount, remaining, bill_list[i]])\n",
    "                state_history_list.append([time_in_h, update_state, action, price, amount, remaining, bill_list[i]])\n",
    "            total_bill_buy_arr= total_bill_buy_arr+ np.array(bill_list)* amount\n",
    "        \n",
    "        \n",
    "        print (time, 'action_name', action_name, 'state', update_state, 'price', price, 'amount', amount, 'prioirty', prioirty, 'total_consumption', total_consumption, 'remaining', total_energy- total_consumption, 'ori_remaining', ori_energy- ori_consumption )\n",
    "        \n",
    "    for i in action_list:\n",
    "        print (i)\n",
    "    total_bill_arr= total_bill_sell_arr- total_bill_buy_arr\n",
    "   \n",
    "    print ('total_bill_arr', total_bill_arr)\n",
    "    return action_list\n",
    "                                  \n",
    "                                  \n",
    "def get_info_in_hour_list(data_list):\n",
    "    a= 100\n",
    "    b= a+ 50                           \n",
    "    rand_range_start= random.randrange(a, b)\n",
    "    target_validation_data_list= []\n",
    "    start_add= False\n",
    "    for i, c in enumerate(data_list[rand_range_start:]):\n",
    "                    \n",
    "        time_in_h= c[0].split(' ')[1]\n",
    "       \n",
    "        if '00:00:00' == time_in_h:\n",
    "           \n",
    "            target_validation_data_list= data_list[rand_range_start+ i: rand_range_start+ i+ 24]\n",
    "            break\n",
    "    \n",
    "    return target_validation_data_list\n",
    "\n",
    "def get_predicted_data_list(predicted_data_list_dir):\n",
    "    with open(predicted_data_list_dir, 'r', newline='') as csvfile:\n",
    "        reader= csv.reader(csvfile, delimiter=',')\n",
    "        data_list= [i for i in reader]\n",
    "     #   data_list= [[i[0], float(i[1]), float(i[2])] for i in reader[1:]]\n",
    "\n",
    "    \n",
    "    return data_list\n",
    "    \n",
    "            \n",
    "                                  \n",
    "        \n",
    "def save_output_data(output_data_dir, data_list):\n",
    "    header= ['time', 'action', 'target_price', 'target_volume']\n",
    "    with open(output_data_dir, 'w', newline='') as csvfile:\n",
    "        writer= csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(data_list)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fdbb536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data                    time generation sonsumption\n",
      "0   2018-01-14 00:00:00        0.0        0.89\n",
      "1   2018-01-14 01:00:00        0.0        0.99\n",
      "2   2018-01-14 02:00:00        0.0         1.0\n",
      "3   2018-01-14 03:00:00        0.0        1.49\n",
      "4   2018-01-14 04:00:00       0.01        4.02\n",
      "5   2018-01-14 05:00:00        0.0        2.19\n",
      "6   2018-01-14 06:00:00        0.0        0.89\n",
      "7   2018-01-14 07:00:00       0.01        0.59\n",
      "8   2018-01-14 08:00:00       1.58        0.71\n",
      "9   2018-01-14 09:00:00       3.16        0.92\n",
      "10  2018-01-14 10:00:00       4.14        0.96\n",
      "11  2018-01-14 11:00:00        4.7        1.34\n",
      "12  2018-01-14 12:00:00       4.89        1.06\n",
      "13  2018-01-14 13:00:00       4.77        1.08\n",
      "14  2018-01-14 14:00:00       4.26        0.79\n",
      "15  2018-01-14 15:00:00       3.22        0.74\n",
      "16  2018-01-14 16:00:00       1.63        0.96\n",
      "17  2018-01-14 17:00:00       0.28        1.11\n",
      "18  2018-01-14 18:00:00       0.01        0.85\n",
      "19  2018-01-14 19:00:00        0.0        0.99\n",
      "20  2018-01-14 20:00:00        0.0        0.94\n",
      "21  2018-01-14 21:00:00        0.0        0.96\n",
      "22  2018-01-14 22:00:00        0.0         0.9\n",
      "23  2018-01-14 23:00:00        0.0        0.89\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "generation_data_dir= os.path.join(os.getcwd(), 'inputs/generation.csv') \n",
    "consumption_data_dir= os.path.join(os.getcwd(), \"inputs/consumption.csv\")\n",
    "init_predict(generation_data_dir, consumption_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cf4a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13:00:00', 0.637409391642348]\n",
      "['12:00:00', 0.6475673597127393]\n",
      "['14:00:00', 0.6742842898112511]\n",
      "['11:00:00', 0.6749518403380358]\n",
      "['15:00:00', 0.7965451418689369]\n",
      "['10:00:00', 0.8287340312085137]\n",
      "['16:00:00', 1.0402577329004117]\n",
      "['09:00:00', 1.2965364601771405]\n",
      "['17:00:00', 1.670783270226639]\n",
      "['08:00:00', 2.880947776478743]\n",
      "['18:00:00', 3.6134152931639703]\n",
      "['07:00:00', 11.287017606971022]\n",
      "['19:00:00', 11.819810235637087]\n",
      "['06:00:00', 108.38405714933175]\n",
      "['05:00:00', 127.49731110513773]\n",
      "['04:00:00', 127.72189709826478]\n",
      "['03:00:00', 139.39848756728887]\n",
      "['01:00:00', 147.5380403786858]\n",
      "['02:00:00', 155.94033861865216]\n",
      "['20:00:00', 156.29306095979013]\n",
      "['00:00:00', 185.9312143034415]\n",
      "['23:00:00', 229.7779037540854]\n",
      "['22:00:00', 281.96527347140227]\n",
      "['21:00:00', 296.0721141029001]\n",
      "test_data                    time generation sonsumption\n",
      "0   2018-01-14 00:00:00        0.0        0.89\n",
      "1   2018-01-14 01:00:00        0.0        0.99\n",
      "2   2018-01-14 02:00:00        0.0         1.0\n",
      "3   2018-01-14 03:00:00        0.0        1.49\n",
      "4   2018-01-14 04:00:00       0.01        4.02\n",
      "5   2018-01-14 05:00:00        0.0        2.19\n",
      "6   2018-01-14 06:00:00        0.0        0.89\n",
      "7   2018-01-14 07:00:00       0.01        0.59\n",
      "8   2018-01-14 08:00:00       1.58        0.71\n",
      "9   2018-01-14 09:00:00       3.16        0.92\n",
      "10  2018-01-14 10:00:00       4.14        0.96\n",
      "11  2018-01-14 11:00:00        4.7        1.34\n",
      "12  2018-01-14 12:00:00       4.89        1.06\n",
      "13  2018-01-14 13:00:00       4.77        1.08\n",
      "14  2018-01-14 14:00:00       4.26        0.79\n",
      "15  2018-01-14 15:00:00       3.22        0.74\n",
      "16  2018-01-14 16:00:00       1.63        0.96\n",
      "17  2018-01-14 17:00:00       0.28        1.11\n",
      "18  2018-01-14 18:00:00       0.01        0.85\n",
      "19  2018-01-14 19:00:00        0.0        0.99\n",
      "20  2018-01-14 20:00:00        0.0        0.94\n",
      "21  2018-01-14 21:00:00        0.0        0.96\n",
      "22  2018-01-14 22:00:00        0.0         0.9\n",
      "23  2018-01-14 23:00:00        0.0        0.89\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "2018-01-14 00:00:00 action_name None state [0, 0] price None amount -0.5755152702331543 prioirty None total_consumption 0.9030802845954895 remaining -0.5755152702331543 ori_remaining -0.5755152702331543\n",
      "2018-01-14 01:00:00 action_name None state [0, 0] price None amount -1.1726047098636627 prioirty None total_consumption 1.8353490233421326 remaining -1.1726047098636627 ori_remaining -1.1726047098636627\n",
      "2018-01-14 02:00:00 action_name None state [0, 0] price None amount -1.7846893072128296 prioirty None total_consumption 2.783604323863983 remaining -1.7846893072128296 ori_remaining -1.7846893072128296\n",
      "2018-01-14 03:00:00 action_name None state [0, 0] price None amount -2.599529206752777 prioirty None total_consumption 3.9343255162239075 remaining -2.599529206752777 ori_remaining -2.599529206752777\n",
      "2018-01-14 04:00:00 action_name None state [0, 0] price None amount -5.299900025129318 prioirty None total_consumption 6.973285496234894 remaining -5.299900025129318 ori_remaining -5.299900025129318\n",
      "2018-01-14 05:00:00 action_name None state [0, 0] price None amount -7.560556083917618 prioirty None total_consumption 9.552501261234283 remaining -7.560556083917618 ori_remaining -7.560556083917618\n",
      "2018-01-14 06:00:00 action_name None state [0, 0] price None amount -8.66473713517189 prioirty None total_consumption 10.9692263007164 remaining -8.66473713517189 ori_remaining -8.66473713517189\n",
      "2018-01-14 07:00:00 action_name None state [0, 0] price None amount -9.290623664855957 prioirty None total_consumption 11.919017612934113 remaining -9.290623664855957 ori_remaining -9.290623664855957\n",
      "2018-01-14 08:00:00 action_name None state [1, 0] price None amount -7.673346757888794 prioirty None total_consumption 12.82292515039444 remaining -7.673346757888794 ori_remaining -7.673346757888794\n",
      "2018-01-14 09:00:00 action_name None state [1, 0] price None amount -4.239280700683594 prioirty None total_consumption 13.826538383960724 remaining -4.239280700683594 ori_remaining -4.239280700683594\n",
      "2018-01-14 10:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 0.6674907684326172 prioirty 5 total_consumption 14.91571456193924 remaining -0.1668726921081536 ori_remaining -0.8343634605407715\n",
      "2018-01-14 11:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 2.248184719085694 prioirty 3 total_consumption 16.236992299556732 remaining 5.05841561794281 ori_remaining 2.1427401304244995\n",
      "2018-01-14 12:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 6.281067630767822 prioirty 1 total_consumption 17.496485888957977 remaining 14.1324021692276 ori_remaining 4.935659050941467\n",
      "2018-01-14 13:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 13.332453717803958 prioirty 0 total_consumption 18.723664224147797 remaining 29.998020865058905 ori_remaining 7.468824028968811\n",
      "2018-01-14 14:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 25.686170274047857 prioirty 2 total_consumption 19.787329733371735 remaining 57.793883116607674 ori_remaining 9.578516006469727\n",
      "2018-01-14 15:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 46.92484676962281 prioirty 4 total_consumption 20.75196486711502 remaining 105.58090523165131 ori_remaining 10.440691351890564\n",
      "2018-01-14 16:00:00 action_name None state [1, 0] price None amount 105.009989145216 prioirty None total_consumption 21.721213221549988 remaining 105.009989145216 ori_remaining 9.869775265455246\n",
      "2018-01-14 17:00:00 action_name None state [1, 0] price None amount 104.10022039246226 prioirty None total_consumption 22.715097665786743 remaining 104.10022039246226 ori_remaining 8.960006512701511\n",
      "2018-01-14 18:00:00 action_name None state [1, 0] price None amount 103.29290722590352 prioirty None total_consumption 23.632300198078156 remaining 103.29290722590352 ori_remaining 8.152693346142769\n",
      "2018-01-14 19:00:00 action_name None state [1, 0] price None amount 102.58047741931344 prioirty None total_consumption 24.56919026374817 remaining 102.58047741931344 ori_remaining 7.440263539552689\n",
      "2018-01-14 20:00:00 action_name None state [1, 0] price None amount 101.93605143111611 prioirty None total_consumption 25.50205433368683 remaining 101.93605143111611 ori_remaining 6.795837551355362\n",
      "in sell time\n",
      "2018-01-14 21:00:00 action_name sell state [1, 0] price 1.2369 amount 0.0 prioirty 0 total_consumption 26.436978042125702 remaining 0.0 ori_remaining 6.150870323181152\n",
      "in sell time\n",
      "2018-01-14 22:00:00 action_name sell state [1, 0] price 1.2369 amount 0.49847984313964844 prioirty 1 total_consumption 27.353697180747986 remaining -1.121579647064209 ori_remaining 5.527770519256592\n",
      "['10:00:00', 'buy', 1.2369, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.3605900000000002, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.48428, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.6079700000000003, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.7316600000000002, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.8553500000000003, 0.6674907684326172]\n",
      "['11:00:00', 'buy', 1.2369, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.3605900000000002, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.48428, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.6079700000000003, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.7316600000000002, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.8553500000000003, 2.248184719085694]\n",
      "['12:00:00', 'buy', 1.2369, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.3605900000000002, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.48428, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.6079700000000003, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.7316600000000002, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.8553500000000003, 6.281067630767822]\n",
      "['13:00:00', 'buy', 1.2369, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.3605900000000002, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.48428, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.6079700000000003, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.7316600000000002, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.8553500000000003, 13.332453717803958]\n",
      "['14:00:00', 'buy', 1.2369, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.3605900000000002, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.48428, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.6079700000000003, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.7316600000000002, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.8553500000000003, 25.686170274047857]\n",
      "['15:00:00', 'buy', 1.2369, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.3605900000000002, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.48428, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.6079700000000003, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.7316600000000002, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.8553500000000003, 46.92484676962281]\n",
      "['21:00:00', 'sell', 1.8553500000000003, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.7316600000000002, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.6079700000000003, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.48428, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.3605900000000002, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.2369, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.8553500000000003, 0.0]\n",
      "['21:00:00', 'sell', 1.7316600000000002, 0.0]\n",
      "['21:00:00', 'sell', 1.6079700000000003, 0.0]\n",
      "['21:00:00', 'sell', 1.48428, 0.0]\n",
      "['21:00:00', 'sell', 1.3605900000000002, 0.0]\n",
      "['21:00:00', 'sell', 1.2369, 0.0]\n",
      "['22:00:00', 'sell', 1.8553500000000003, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.7316600000000002, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.6079700000000003, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.48428, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.3605900000000002, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.2369, 0.49847984313964844]\n",
      "total_bill_arr [71.17633711 70.35387898 69.53142086 68.70896274 67.88650462 67.06404649]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_name= 'target0.csv'\n",
    "target_dir= os.path.join(os.getcwd(), 'energy_data')\n",
    "train_data_dir= os.path.join(target_dir, data_name)\n",
    "predicted_data_dir= os.path.join(os.getcwd(), 'predict_data.csv')\n",
    "\n",
    "\n",
    "consumption_data_name= 'consumption.csv'\n",
    "generation_data_name= 'generation.csv'\n",
    "bid_result_data_name= 'bidresult.csv'\n",
    "output_dir= os.path.join(os.getcwd(), 'output.csv')\n",
    "            \n",
    "data_list= get_all_data(target_dir)\n",
    "gen_bidresult(bid_result_data_name)\n",
    "\n",
    "gen_val_data(data_list, consumption_data_name, generation_data_name)\n",
    "                      \n",
    "request_gen_rate_list= get_request_gen_rate(data_list)                      \n",
    "get_peak_time(data_list)\n",
    "#get_gen_consum_progress(data_list)\n",
    "#info_in_hour_list= get_info_in_hour_list(data_list)\n",
    "\n",
    "\n",
    "generation_data_dir= os.path.join(os.getcwd(), \"inputs/generation.csv\") \n",
    "consumption_data_dir= os.path.join(os.getcwd(), \"inputs/consumption.csv\")\n",
    "init_predict(generation_data_dir, consumption_data_dir)\n",
    "\n",
    "predict_data_list= get_predicted_data_list(predicted_data_dir)\n",
    "action_list= init_agent(predict_data_list, request_gen_rate_list)\n",
    "    \n",
    "output(output_dir, action_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bc9b47e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--consumption CONSUMPTION]\n",
      "                             [--generation GENERATION] [--bidresult BIDRESULT]\n",
      "                             [--output OUTPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/chois/Library/Jupyter/runtime/kernel-e83fc039-3dcb-4539-9bf0-4ddfc144cf37.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chois/opt/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = config()\n",
    "    \n",
    "    consumption_data_dir= args.consumption\n",
    "    generation_data_dir= args.generation\n",
    "    bidresult_data_dir= args.bidresult\n",
    "    output_dir= args.output\n",
    "    predicted_data_dir= os.path.join(os.getcwd(), 'predict_data.csv')\n",
    "    \n",
    "    target_dir= os.path.join(os.getcwd(), 'energy_data')\n",
    "    data_list= get_all_data(target_dir)\n",
    "    request_gen_rate_list= get_request_gen_rate(data_list) \n",
    "    \n",
    "    init_predict(generation_data_dir, consumption_data_dir)                       \n",
    "    predict_data_list= get_predicted_data_list(predicted_data_dir)\n",
    "    action_list= init_agent(predict_data_list, request_gen_rate_list)\n",
    "    output(output_dir, action_list)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8872dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "['13:00:00', 0.637409391642348]\n",
      "['12:00:00', 0.6475673597127393]\n",
      "['14:00:00', 0.6742842898112511]\n",
      "['11:00:00', 0.6749518403380358]\n",
      "['15:00:00', 0.7965451418689369]\n",
      "['10:00:00', 0.8287340312085137]\n",
      "['16:00:00', 1.0402577329004117]\n",
      "['09:00:00', 1.2965364601771405]\n",
      "['17:00:00', 1.670783270226639]\n",
      "['08:00:00', 2.880947776478743]\n",
      "['18:00:00', 3.6134152931639703]\n",
      "['07:00:00', 11.287017606971022]\n",
      "['19:00:00', 11.819810235637087]\n",
      "['06:00:00', 108.38405714933175]\n",
      "['05:00:00', 127.49731110513773]\n",
      "['04:00:00', 127.72189709826478]\n",
      "['03:00:00', 139.39848756728887]\n",
      "['01:00:00', 147.5380403786858]\n",
      "['02:00:00', 155.94033861865216]\n",
      "['20:00:00', 156.29306095979013]\n",
      "['00:00:00', 185.9312143034415]\n",
      "['23:00:00', 229.7779037540854]\n",
      "['22:00:00', 281.96527347140227]\n",
      "['21:00:00', 296.0721141029001]\n",
      "test_data                    time generation sonsumption\n",
      "0   2018-01-14 00:00:00        0.0        0.89\n",
      "1   2018-01-14 01:00:00        0.0        0.99\n",
      "2   2018-01-14 02:00:00        0.0         1.0\n",
      "3   2018-01-14 03:00:00        0.0        1.49\n",
      "4   2018-01-14 04:00:00       0.01        4.02\n",
      "5   2018-01-14 05:00:00        0.0        2.19\n",
      "6   2018-01-14 06:00:00        0.0        0.89\n",
      "7   2018-01-14 07:00:00       0.01        0.59\n",
      "8   2018-01-14 08:00:00       1.58        0.71\n",
      "9   2018-01-14 09:00:00       3.16        0.92\n",
      "10  2018-01-14 10:00:00       4.14        0.96\n",
      "11  2018-01-14 11:00:00        4.7        1.34\n",
      "12  2018-01-14 12:00:00       4.89        1.06\n",
      "13  2018-01-14 13:00:00       4.77        1.08\n",
      "14  2018-01-14 14:00:00       4.26        0.79\n",
      "15  2018-01-14 15:00:00       3.22        0.74\n",
      "16  2018-01-14 16:00:00       1.63        0.96\n",
      "17  2018-01-14 17:00:00       0.28        1.11\n",
      "18  2018-01-14 18:00:00       0.01        0.85\n",
      "19  2018-01-14 19:00:00        0.0        0.99\n",
      "20  2018-01-14 20:00:00        0.0        0.94\n",
      "21  2018-01-14 21:00:00        0.0        0.96\n",
      "22  2018-01-14 22:00:00        0.0         0.9\n",
      "23  2018-01-14 23:00:00        0.0        0.89\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "2018-01-14 00:00:00 action_name None state [0, 0] price None amount -0.5755152702331543 prioirty None total_consumption 0.9030802845954895 remaining -0.5755152702331543 ori_remaining -0.5755152702331543\n",
      "2018-01-14 01:00:00 action_name None state [0, 0] price None amount -1.1726047098636627 prioirty None total_consumption 1.8353490233421326 remaining -1.1726047098636627 ori_remaining -1.1726047098636627\n",
      "2018-01-14 02:00:00 action_name None state [0, 0] price None amount -1.7846893072128296 prioirty None total_consumption 2.783604323863983 remaining -1.7846893072128296 ori_remaining -1.7846893072128296\n",
      "2018-01-14 03:00:00 action_name None state [0, 0] price None amount -2.599529206752777 prioirty None total_consumption 3.9343255162239075 remaining -2.599529206752777 ori_remaining -2.599529206752777\n",
      "2018-01-14 04:00:00 action_name None state [0, 0] price None amount -5.299900025129318 prioirty None total_consumption 6.973285496234894 remaining -5.299900025129318 ori_remaining -5.299900025129318\n",
      "2018-01-14 05:00:00 action_name None state [0, 0] price None amount -7.560556083917618 prioirty None total_consumption 9.552501261234283 remaining -7.560556083917618 ori_remaining -7.560556083917618\n",
      "2018-01-14 06:00:00 action_name None state [0, 0] price None amount -8.66473713517189 prioirty None total_consumption 10.9692263007164 remaining -8.66473713517189 ori_remaining -8.66473713517189\n",
      "2018-01-14 07:00:00 action_name None state [0, 0] price None amount -9.290623664855957 prioirty None total_consumption 11.919017612934113 remaining -9.290623664855957 ori_remaining -9.290623664855957\n",
      "2018-01-14 08:00:00 action_name None state [1, 0] price None amount -7.673346757888794 prioirty None total_consumption 12.82292515039444 remaining -7.673346757888794 ori_remaining -7.673346757888794\n",
      "2018-01-14 09:00:00 action_name None state [1, 0] price None amount -4.239280700683594 prioirty None total_consumption 13.826538383960724 remaining -4.239280700683594 ori_remaining -4.239280700683594\n",
      "2018-01-14 10:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 0.6674907684326172 prioirty 5 total_consumption 14.91571456193924 remaining -0.1668726921081536 ori_remaining -0.8343634605407715\n",
      "2018-01-14 11:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 2.248184719085694 prioirty 3 total_consumption 16.236992299556732 remaining 5.05841561794281 ori_remaining 2.1427401304244995\n",
      "2018-01-14 12:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 6.281067630767822 prioirty 1 total_consumption 17.496485888957977 remaining 14.1324021692276 ori_remaining 4.935659050941467\n",
      "2018-01-14 13:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 13.332453717803958 prioirty 0 total_consumption 18.723664224147797 remaining 29.998020865058905 ori_remaining 7.468824028968811\n",
      "2018-01-14 14:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 25.686170274047857 prioirty 2 total_consumption 19.787329733371735 remaining 57.793883116607674 ori_remaining 9.578516006469727\n",
      "2018-01-14 15:00:00 action_name buy state [1, 0] price 1.8553500000000003 amount 46.92484676962281 prioirty 4 total_consumption 20.75196486711502 remaining 105.58090523165131 ori_remaining 10.440691351890564\n",
      "2018-01-14 16:00:00 action_name None state [1, 0] price None amount 105.009989145216 prioirty None total_consumption 21.721213221549988 remaining 105.009989145216 ori_remaining 9.869775265455246\n",
      "2018-01-14 17:00:00 action_name None state [1, 0] price None amount 104.10022039246226 prioirty None total_consumption 22.715097665786743 remaining 104.10022039246226 ori_remaining 8.960006512701511\n",
      "2018-01-14 18:00:00 action_name None state [1, 0] price None amount 103.29290722590352 prioirty None total_consumption 23.632300198078156 remaining 103.29290722590352 ori_remaining 8.152693346142769\n",
      "2018-01-14 19:00:00 action_name None state [1, 0] price None amount 102.58047741931344 prioirty None total_consumption 24.56919026374817 remaining 102.58047741931344 ori_remaining 7.440263539552689\n",
      "2018-01-14 20:00:00 action_name None state [1, 0] price None amount 101.93605143111611 prioirty None total_consumption 25.50205433368683 remaining 101.93605143111611 ori_remaining 6.795837551355362\n",
      "2018-01-14 22:00:00 action_name sell state [1, 0] price 1.2369 amount 0.49847984313964844 prioirty 1 total_consumption 27.353697180747986 remaining -1.121579647064209 ori_remaining 5.527770519256592\n",
      "['10:00:00', 'buy', 1.2369, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.3605900000000002, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.48428, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.6079700000000003, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.7316600000000002, 0.6674907684326172]\n",
      "['10:00:00', 'buy', 1.8553500000000003, 0.6674907684326172]\n",
      "['11:00:00', 'buy', 1.2369, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.3605900000000002, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.48428, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.6079700000000003, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.7316600000000002, 2.248184719085694]\n",
      "['11:00:00', 'buy', 1.8553500000000003, 2.248184719085694]\n",
      "['12:00:00', 'buy', 1.2369, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.3605900000000002, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.48428, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.6079700000000003, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.7316600000000002, 6.281067630767822]\n",
      "['12:00:00', 'buy', 1.8553500000000003, 6.281067630767822]\n",
      "['13:00:00', 'buy', 1.2369, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.3605900000000002, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.48428, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.6079700000000003, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.7316600000000002, 13.332453717803958]\n",
      "['13:00:00', 'buy', 1.8553500000000003, 13.332453717803958]\n",
      "['14:00:00', 'buy', 1.2369, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.3605900000000002, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.48428, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.6079700000000003, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.7316600000000002, 25.686170274047857]\n",
      "['14:00:00', 'buy', 1.8553500000000003, 25.686170274047857]\n",
      "['15:00:00', 'buy', 1.2369, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.3605900000000002, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.48428, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.6079700000000003, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.7316600000000002, 46.92484676962281]\n",
      "['15:00:00', 'buy', 1.8553500000000003, 46.92484676962281]\n",
      "['21:00:00', 'sell', 1.8553500000000003, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.7316600000000002, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.6079700000000003, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.48428, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.3605900000000002, 101.2910842029419]\n",
      "['21:00:00', 'sell', 1.2369, 101.2910842029419]\n",
      "['22:00:00', 'sell', 1.8553500000000003, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.7316600000000002, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.6079700000000003, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.48428, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.3605900000000002, 0.49847984313964844]\n",
      "['22:00:00', 'sell', 1.2369, 0.49847984313964844]\n",
      "total_bill_arr [71.17633711 70.35387898 69.53142086 68.70896274 67.88650462 67.06404649]\n"
     ]
    }
   ],
   "source": [
    "!python energy_trader.py --generation /Users/chois/MLDS-HW2-2022/inputs/generation.csv  --consumption /Users/chois/MLDS-HW2-2022/inputs/consumption.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf724bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "python energy_trader.py --output /Users/chois/MLDS-HW2-2022/inputs/output_test.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
